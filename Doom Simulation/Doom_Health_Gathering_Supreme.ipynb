{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAMwza0d5QVj"
      },
      "source": [
        "## VizDoom Health Gathering Supreme\n",
        "\n",
        "This notebook focuses on setting up and training an agent in the Health Gathering Supreme scenario of VizDoom, a 3D first-person shooter environment commonly used in reinforcement learning research. This scenario is especially interesting due to its sparse reward structure, where the agent must survive as long as possible by collecting health kits while constantly taking damage from the acid floor. Agent gets rewared based on its ability to pathfind towards health kits crucial for its survival."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"https://huggingface.co/datasets/huggingface-deep-rl-course/course-images/resolve/main/en/unit9/Health-Gathering-Supreme.png\" alt=\"Health-Gathering-Supreme\"/>\n",
        "\n",
        "\n",
        "Map is a rectangle containing walls and with acid that **hurts the player periodically**. Initially there are some medkits spread uniformly over the map. A new medkit falls from the skies every now and then. **Medkits heal some portions of player's health** - to survive agent needs to pick them up. Episode finishes after player's death or on timeout.\n",
        "\n",
        "Further configuration:\n",
        "- Living_reward = 1\n",
        "- 3 available buttons: turn left, turn right, move forward\n",
        "- 1 available game variable: HEALTH\n",
        "- death penalty = 100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "markdown"
        }
      },
      "source": [
        "### Installation and Setup\n",
        "\n",
        "In this section, we will install all the necessary system dependencies and Python packages required to run the ViZDoom Health Gathering Supreme environment and train reinforcement learning agents using Sample Factory.\n",
        "\n",
        "#### Why Sample Factory?\n",
        "To run multiple environments in parallel. Lets us implement APPO (Asynchronous Proximal Policy Optimization), which is a highly optimized version of PPO, suitable for complex 3D environments like Doom."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RJMxkaldwIVx"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%%bash\n",
        "apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n",
        "nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n",
        "libopenal-dev timidity libwildmidi-dev unzip ffmpeg\n",
        "apt-get install libboost-all-dev\n",
        "apt-get install liblua5.1-dev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbqfPZnIsvA6"
      },
      "outputs": [],
      "source": [
        "!pip install faster-fifo==1.4.2\n",
        "!pip install vizdoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "alxUt7Au-O8e"
      },
      "outputs": [],
      "source": [
        "!pip install sample-factory==2.1.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "torch.load 2.6 (default) will set the parameter -> weights_only = True by default which prevents it from loading custom/np objects. To avoid this we need to downgrade torch. More info: https://docs.pytorch.org/docs/stable/generated/torch.load.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SakGBuQ0u0zA"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jizouGpghUZ"
      },
      "source": [
        "### Setting up the Doom Environment in sample-factory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bCgZbeiavcDU"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "\n",
        "from sample_factory.algo.utils.context import global_model_factory\n",
        "from sample_factory.cfg.arguments import parse_full_cfg, parse_sf_args\n",
        "from sample_factory.envs.env_utils import register_env\n",
        "from sample_factory.train import run_rl\n",
        "\n",
        "from sf_examples.vizdoom.doom.doom_model import make_vizdoom_encoder\n",
        "from sf_examples.vizdoom.doom.doom_params import add_doom_env_args, doom_override_defaults\n",
        "from sf_examples.vizdoom.doom.doom_utils import DOOM_ENVS, make_doom_env_from_spec\n",
        "\n",
        "\n",
        "# Registers ViZDoom environments\n",
        "def register_vizdoom_envs():\n",
        "    for env_spec in DOOM_ENVS:\n",
        "        make_env_func = functools.partial(make_doom_env_from_spec, env_spec)\n",
        "        register_env(env_spec.name, make_env_func)\n",
        "\n",
        "def register_vizdoom_models():\n",
        "    global_model_factory().register_encoder_factory(make_vizdoom_encoder)\n",
        "\n",
        "\n",
        "def register_vizdoom_components():\n",
        "    register_vizdoom_envs()\n",
        "    register_vizdoom_models()\n",
        "\n",
        "# parse the command line args and create a config\n",
        "def parse_vizdoom_cfg(argv=None, evaluation=False):\n",
        "    parser, _ = parse_sf_args(argv=argv, evaluation=evaluation)\n",
        "    # lets you specify the parameters for the environment\n",
        "    add_doom_env_args(parser)\n",
        "    # override defaults\n",
        "    doom_override_defaults(parser)\n",
        "    final_cfg = parse_full_cfg(parser, argv)\n",
        "    return final_cfg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siHZZ34DiZEp"
      },
      "source": [
        "### Training the agent\n",
        "Toggle the values of **num_workers** and **num_envs_er_worker** as much as your device can handle. The higher the better, however, requries more processing power.\n",
        "**gamma** is set to 0.98 to help the agent focus on immediate rewards as the health kits are random anyways.\n",
        "**train_for_env_steps** should be set high enough.\n",
        "\n",
        "Suggestions, could change learning_rate, increase rollout to stabilize learning early on, increase num_epochs (default = 1) for sample efficiency etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_TeicMvyKHP"
      },
      "outputs": [],
      "source": [
        "register_vizdoom_components()\n",
        "env = \"doom_health_gathering_supreme\"\n",
        "cfg = parse_vizdoom_cfg(argv=[f\"--env={env}\", \"--num_workers=16\", \"--num_envs_per_worker=8\", \"--gamma=0.98\", \"--rollout=32\", \"--learning_rate=0.0001\",\"--train_for_env_steps=33000000\"])\n",
        "\n",
        "status = run_rl(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5L0nBS9e_jqC"
      },
      "source": [
        "### Evaluate the Performance and save the video\n",
        "While evaluating, you only need to run 1 worker. Ensure save_video is enabled, to see the agent playing VizDoom"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MGSA4Kg5_i0j"
      },
      "outputs": [],
      "source": [
        "from sample_factory.enjoy import enjoy\n",
        "cfg = parse_vizdoom_cfg(argv=[f\"--env={env}\", \"--num_workers=1\", \"--save_video\", \"--no_render\", \"--max_num_episodes=10\"], evaluation=True)\n",
        "status = enjoy(cfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lj5L1x0WLxwB"
      },
      "source": [
        "### View \"replay.mp4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsXhBY7JNOdJ"
      },
      "outputs": [],
      "source": [
        "from base64 import b64encode\n",
        "from IPython.display import HTML\n",
        "\n",
        "mp4 = open('/content/train_dir/default_experiment/replay.mp4','rb').read()\n",
        "data_url = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=640 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % data_url)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A4pf_1VwPqR"
      },
      "source": [
        "Model Card available on https://huggingface.co/loke-07/vizdoom_health_gathering_supreme"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "PU4FVzaoM6fC",
        "nB68Eb9UgC94",
        "ez5UhUtYcWXF",
        "sgRy6wnrgnij"
      ],
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
